{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joeragaa/Image-classification/blob/main/cvision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U0YYD0ZJtau"
      },
      "source": [
        "# Image classification on the CIFAR100 dataset\n",
        "This notebook compares the performance of multiple classifiers on the task of image classification with the CIFAR100 dataset. \n",
        "The classifiers used are SVM, KNN, Kmeans and CNN.\n",
        "KNN and Kmeans classifiers were built using numpy and imported from a custom file. SVM classifier is used from Scikit-learn and lastly the convolutional neural network model was built and trained using tensoflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOUnUaDcFr3G",
        "outputId": "9b831fd1-0818-4ea8-cee9-51d88c2086da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mounting google drive to import helper module later on\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27UFzZuK8QKg",
        "outputId": "9c9d294b-a655-4d55-887e-19ca00b6c5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "169017344/169001437 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1048832   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,093,924\n",
            "Trainable params: 1,093,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 14s 4ms/step - loss: 4.0036 - accuracy: 0.0922 - val_loss: 3.3895 - val_accuracy: 0.1972\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.3873 - accuracy: 0.1865 - val_loss: 3.0217 - val_accuracy: 0.2653\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.0974 - accuracy: 0.2413 - val_loss: 2.8249 - val_accuracy: 0.3021\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.8986 - accuracy: 0.2742 - val_loss: 2.7260 - val_accuracy: 0.3208\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.7536 - accuracy: 0.3018 - val_loss: 2.6021 - val_accuracy: 0.3501\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.6334 - accuracy: 0.3250 - val_loss: 2.5533 - val_accuracy: 0.3604\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.5224 - accuracy: 0.3455 - val_loss: 2.5347 - val_accuracy: 0.3616\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.4241 - accuracy: 0.3700 - val_loss: 2.4920 - val_accuracy: 0.3673\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.3234 - accuracy: 0.3866 - val_loss: 2.4760 - val_accuracy: 0.3753\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.2466 - accuracy: 0.4011 - val_loss: 2.4782 - val_accuracy: 0.3767\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.1541 - accuracy: 0.4227 - val_loss: 2.4640 - val_accuracy: 0.3760\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.0771 - accuracy: 0.4374 - val_loss: 2.4742 - val_accuracy: 0.3787\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.0007 - accuracy: 0.4519 - val_loss: 2.4658 - val_accuracy: 0.3833\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.9212 - accuracy: 0.4684 - val_loss: 2.5054 - val_accuracy: 0.3855\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8665 - accuracy: 0.4799 - val_loss: 2.5749 - val_accuracy: 0.3761\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8005 - accuracy: 0.4929 - val_loss: 2.5528 - val_accuracy: 0.3820\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7415 - accuracy: 0.5073 - val_loss: 2.6016 - val_accuracy: 0.3800\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6820 - accuracy: 0.5230 - val_loss: 2.6405 - val_accuracy: 0.3737\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6185 - accuracy: 0.5337 - val_loss: 2.6850 - val_accuracy: 0.3759\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.5667 - accuracy: 0.5428 - val_loss: 2.6802 - val_accuracy: 0.3800\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.5202 - accuracy: 0.5569 - val_loss: 2.7755 - val_accuracy: 0.3694\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4725 - accuracy: 0.5664 - val_loss: 2.7552 - val_accuracy: 0.3790\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4267 - accuracy: 0.5789 - val_loss: 2.8283 - val_accuracy: 0.3689\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.3799 - accuracy: 0.5898 - val_loss: 2.9094 - val_accuracy: 0.3740\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.3383 - accuracy: 0.5994 - val_loss: 2.9529 - val_accuracy: 0.3722\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.3122 - accuracy: 0.6046 - val_loss: 2.9419 - val_accuracy: 0.3670\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2733 - accuracy: 0.6171 - val_loss: 2.9901 - val_accuracy: 0.3666\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2349 - accuracy: 0.6262 - val_loss: 3.1320 - val_accuracy: 0.3592\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2133 - accuracy: 0.6278 - val_loss: 3.2543 - val_accuracy: 0.3687\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1626 - accuracy: 0.6470 - val_loss: 3.1813 - val_accuracy: 0.3627\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1469 - accuracy: 0.6459 - val_loss: 3.2938 - val_accuracy: 0.3592\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1113 - accuracy: 0.6556 - val_loss: 3.3604 - val_accuracy: 0.3546\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0972 - accuracy: 0.6591 - val_loss: 3.4384 - val_accuracy: 0.3576\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0671 - accuracy: 0.6689 - val_loss: 3.4048 - val_accuracy: 0.3572\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0500 - accuracy: 0.6709 - val_loss: 3.5409 - val_accuracy: 0.3541\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0197 - accuracy: 0.6803 - val_loss: 3.5876 - val_accuracy: 0.3563\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0048 - accuracy: 0.6865 - val_loss: 3.5847 - val_accuracy: 0.3549\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9896 - accuracy: 0.6899 - val_loss: 3.6988 - val_accuracy: 0.3539\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9652 - accuracy: 0.6933 - val_loss: 3.7492 - val_accuracy: 0.3533\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9467 - accuracy: 0.6988 - val_loss: 3.8917 - val_accuracy: 0.3505\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9170 - accuracy: 0.7074 - val_loss: 3.8838 - val_accuracy: 0.3511\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9233 - accuracy: 0.7065 - val_loss: 3.8914 - val_accuracy: 0.3468\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9014 - accuracy: 0.7122 - val_loss: 3.9903 - val_accuracy: 0.3455\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8723 - accuracy: 0.7210 - val_loss: 4.0483 - val_accuracy: 0.3500\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8722 - accuracy: 0.7209 - val_loss: 4.1002 - val_accuracy: 0.3489\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8513 - accuracy: 0.7247 - val_loss: 4.1680 - val_accuracy: 0.3471\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8471 - accuracy: 0.7272 - val_loss: 4.1977 - val_accuracy: 0.3403\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8292 - accuracy: 0.7327 - val_loss: 4.4323 - val_accuracy: 0.3449\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8104 - accuracy: 0.7384 - val_loss: 4.2888 - val_accuracy: 0.3420\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8091 - accuracy: 0.7400 - val_loss: 4.3867 - val_accuracy: 0.3437\n",
            "Test loss: 4.246292591094971 / Test accuracy: 0.350600004196167\n"
          ]
        }
      ],
      "source": [
        "#the first classfier used is the CNN\n",
        "import tensorflow as tf\n",
        "import matplotlib as plt\n",
        "\n",
        "#Init\n",
        "batch_size = 50\n",
        "no_epochs = 50\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "#load cifar100 dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "#scale valuse from 0 to 1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "#Build convolutional network\n",
        "#network with two stages of convolution and max pooling followed\n",
        "#by a hidden layer with 256 nodes and a 50% dropout to prevent overfitting\n",
        "#followed by output layer with 100 nodes represeting the 100 classes of the dataset\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "     tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "\n",
        "     tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "     tf.keras.layers.Dropout(0.5),\n",
        "     tf.keras.layers.Dense(100, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "print(model.summary())\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "#train data\n",
        "history = model.fit(X_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_split=validation_split)\n",
        "\n",
        "#saving the trained model\n",
        "model.save(\"cnn_model.h5\")\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00PBoQAmEeq0"
      },
      "outputs": [],
      "source": [
        "# for the following classifiers HOG features are extracted first and then the classifer\n",
        "# is trained in the produced features.\n",
        "# the feature vector produced is loaded into a pandas dataframe and saved to csv file \n",
        "# for further computation outside the notebook if desired.\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from skimage.feature import hog\n",
        "dataset = tf.keras.datasets.cifar100\n",
        "(x_train, y_train), (x_test, y_test) = dataset.load_data()\n",
        "#extract hog features from images in the dataset\n",
        "x_train_features = list(map(lambda x: hog(x,orientations=9, pixels_per_cell=(4, 4),\n",
        "                     cells_per_block=(2, 2), visualize=False,multichannel = True),x_train))\n",
        "x_test_features = list(map(lambda x: hog(x,orientations=9, pixels_per_cell=(4, 4),\n",
        "                     cells_per_block=(2, 2), visualize=False,multichannel = True),x_test))\n",
        "dataframe = pd.DataFrame(x_train_features)\n",
        "dataframe['label'] = y_train\n",
        "dataframe.to_csv('cifar100_train_hog.csv')\n",
        "dataframe_test = pd.DataFrame(x_test_features)\n",
        "dataframe_test['label'] = y_test\n",
        "dataframe_test.to_csv('cifar100_test_hog.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1BDiuqS2-ZK",
        "outputId": "de772479-0fdf-4484-8f0a-6942455d122d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knn accuracy: 0.2014\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import helper\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from skimage.feature import hog\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "X_train = np.array(list(map(lambda x: hog(x,orientations=9, pixels_per_cell=(4, 4),\n",
        "                    cells_per_block=(2, 2), visualize=False,multichannel = True),X_train)))\n",
        "X_test = np.array(list(map(lambda x: hog(x,orientations=9, pixels_per_cell=(4, 4),\n",
        "                     cells_per_block=(2, 2), visualize=False,multichannel = True),X_test)))\n",
        "\n",
        "\n",
        "knn_classifier = helper.knn(x_train=X_train, y_train=y_train, k=5)\n",
        "pred = knn_classifier.predict(x_test=X_test)\n",
        "print(f\"knn accuracy: {accuracy_score(y_test, pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpRl5YG__lH4",
        "outputId": "1579c8ef-28cc-4939-b7c0-52285d07a990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kmeans accuracy: 0.1134\n"
          ]
        }
      ],
      "source": [
        "kmeans_classifier = helper.kmeans(X_train, y_train, 100, iter=50)\n",
        "kmeans_pred = kmeans_classifier.predict(x_test=X_test).flatten()\n",
        "print(f\"kmeans accuracy: {accuracy_score(y_test.flatten(), kmeans_pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CgWVd5U_q8v",
        "outputId": "c9a65fa6-64be-4281-aa26-d7f407485962"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "svm accuracy: 0.1541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "svm_classifier = svm.LinearSVC(C=5,max_iter=100)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "print(f\"svm accuracy: {accuracy_score(y_test.flatten(), svm_predictions)}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cvision.ipynb",
      "provenance": [],
      "mount_file_id": "1_JqZec6cC6ryDsLSmQd-tg2QHLp6xj8y",
      "authorship_tag": "ABX9TyN8uMOcw/KIrL+8mbQRJqt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}